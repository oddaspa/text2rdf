{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d92b0692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efe910",
   "metadata": {},
   "source": [
    "# LIAR DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3586ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(part):\n",
    "    columns = [\"id\", \"label\", \"text\", \"subject\", \"speaker\", \"job\", \"state\", \"party\", \"int0\", \"int1\", \"int2\", \"int3\", \"int4\", \"context\"]\n",
    "    return pd.read_csv(\"./liar_dataset/\" + part + \".tsv\", sep=\"\\t\", names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b513c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_csv(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ada4d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_label(label):\n",
    "    if label in [\"pants-fire\", \"false\", \"barely-true\"]:\n",
    "        return \"false\"\n",
    "    else:\n",
    "        return \"true\"\n",
    "    \n",
    "def clean_df(df):\n",
    "    # 6 labels pants-fire, false, barely-true, half-true, mostly-true, true\n",
    "    df[\"label\"] = df[\"label\"].apply(lambda label: sort_label(label))\n",
    "    \n",
    "    # per https://arxiv.org/pdf/1905.04749.pdf they only use text and label\n",
    "    filtered_df=df.loc[:, [\"id\", \"label\", \"text\"]]\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab1fc877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11972.json</td>\n",
       "      <td>true</td>\n",
       "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11685.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Wisconsin is on pace to double the number of l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11096.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says John McCain has done nothing to help the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5209.json</td>\n",
       "      <td>true</td>\n",
       "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9524.json</td>\n",
       "      <td>false</td>\n",
       "      <td>When asked by a reporter whether hes at the ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>7334.json</td>\n",
       "      <td>true</td>\n",
       "      <td>Says his budget provides the highest state fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>9788.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Ive been here almost every day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>10710.json</td>\n",
       "      <td>false</td>\n",
       "      <td>In the early 1980s, Sen. Edward Kennedy secret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>3186.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says an EPA permit languished under Strickland...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>6743.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the governor is going around the state ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1267 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  label                                               text\n",
       "0     11972.json   true  Building a wall on the U.S.-Mexico border will...\n",
       "1     11685.json  false  Wisconsin is on pace to double the number of l...\n",
       "2     11096.json  false  Says John McCain has done nothing to help the ...\n",
       "3      5209.json   true  Suzanne Bonamici supports a plan that will cut...\n",
       "4      9524.json  false  When asked by a reporter whether hes at the ce...\n",
       "...          ...    ...                                                ...\n",
       "1262   7334.json   true  Says his budget provides the highest state fun...\n",
       "1263   9788.json  false                    Ive been here almost every day.\n",
       "1264  10710.json  false  In the early 1980s, Sen. Edward Kennedy secret...\n",
       "1265   3186.json  false  Says an EPA permit languished under Strickland...\n",
       "1266   6743.json  false  Says the governor is going around the state ta...\n",
       "\n",
       "[1267 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a0a0972",
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in [\"train\", \"test\", \"valid\"]:\n",
    "    df = load_csv(part)\n",
    "    df = clean_df(df)\n",
    "    df.to_csv(\"./liar_dataset/clean_\" + part + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fbe5d1",
   "metadata": {},
   "source": [
    "## Post processing\n",
    "Clean output from triple extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0925942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bug_clean(df):\n",
    "    condition = np.logical_and(df.triple.notna(), df.text.isna())\n",
    "    indxs = df[condition][\"Unnamed: 0\"].values\n",
    "    triples = df[condition][\"triple\"].values\n",
    "    df.loc[indxs, \"triple\"] = triples\n",
    "    df.drop(df.index[condition], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "d18e9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob(\"./liar_dataset_triples/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "11acfd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()\n",
    "for path in paths:\n",
    "    if not path.__contains__(\"train\"):\n",
    "        continue\n",
    "    curr_df = pd.read_csv(path)\n",
    "    curr_df = bug_clean(curr_df)\n",
    "    main_df = pd.concat([main_df, curr_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "62809f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df.drop(columns=list(set(main_df.columns.values) ^ set([\"id\", \"label\", \"text\", \"triple\"]))).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "d75ae9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.to_csv(\"./liar_dataset_triples/main_train_clean_triples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09911d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_triples(df):\n",
    "    return 1 - sum(df.triple.isna()) / df.shape[0]\n",
    "\n",
    "def avg_word_count(df):\n",
    "    tot = 0\n",
    "    for sent in df.text.values:\n",
    "        tot += len(sent.split(\" \"))\n",
    "    return tot / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae5ab88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob(\"./liar_dataset_triples/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d36b77a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = []\n",
    "for indx, path in enumerate(paths):\n",
    "    if path.__contains__(\"clean_train_triple\"):\n",
    "        drops.append(indx)\n",
    "paths = np.delete(paths, drops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c5998ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: test. avg sent length: 18.24 words. percent triples: 11.68%.\n",
      "dataset: valid. avg sent length: 17.93 words. percent triples: 11.06%.\n",
      "dataset: train. avg sent length: 17.97 words. percent triples: 3.39%.\n"
     ]
    }
   ],
   "source": [
    "for path in paths:\n",
    "    name = \"train\"\n",
    "    if path.__contains__(\"test\"):\n",
    "        name = \"test\"\n",
    "    if path.__contains__(\"valid\"):\n",
    "        name = \"valid\"\n",
    "    df = pd.read_csv(path)    \n",
    "    df = bug_clean(df)\n",
    "    p_triples = percent_triples(df)\n",
    "    sent_size = avg_word_count(df)\n",
    "    print(f\"dataset: {name}. avg sent length: {sent_size:.2f} words. percent triples: {p_triples*100:.2f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "475da1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>triple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2635.json</td>\n",
       "      <td>False</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10540.json</td>\n",
       "      <td>True</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>324.json</td>\n",
       "      <td>True</td>\n",
       "      <td>Hillary Clinton agrees with John McCain by vot...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1123.json</td>\n",
       "      <td>False</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9028.json</td>\n",
       "      <td>True</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10234</th>\n",
       "      <td>2434</td>\n",
       "      <td>1592.json</td>\n",
       "      <td>True</td>\n",
       "      <td>Under the ruling of the Supreme Court, any lob...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10235</th>\n",
       "      <td>2435</td>\n",
       "      <td>5473.json</td>\n",
       "      <td>True</td>\n",
       "      <td>There are a larger number of shark attacks in ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10236</th>\n",
       "      <td>2436</td>\n",
       "      <td>3408.json</td>\n",
       "      <td>True</td>\n",
       "      <td>Democrats have now become the party of the Atl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10237</th>\n",
       "      <td>2437</td>\n",
       "      <td>3959.json</td>\n",
       "      <td>True</td>\n",
       "      <td>Says an alternative to Social Security that op...</td>\n",
       "      <td>[['County', 'location/hud_county_place/county'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10238</th>\n",
       "      <td>2438</td>\n",
       "      <td>2253.json</td>\n",
       "      <td>False</td>\n",
       "      <td>On lifting the U.S. Cuban embargo and allowing...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10239 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0          id  label  \\\n",
       "0               0   2635.json  False   \n",
       "1               1  10540.json   True   \n",
       "2               2    324.json   True   \n",
       "3               3   1123.json  False   \n",
       "4               4   9028.json   True   \n",
       "...           ...         ...    ...   \n",
       "10234        2434   1592.json   True   \n",
       "10235        2435   5473.json   True   \n",
       "10236        2436   3408.json   True   \n",
       "10237        2437   3959.json   True   \n",
       "10238        2438   2253.json  False   \n",
       "\n",
       "                                                    text  \\\n",
       "0      Says the Annies List political group supports ...   \n",
       "1      When did the decline of coal start? It started...   \n",
       "2      Hillary Clinton agrees with John McCain by vot...   \n",
       "3      Health care reform legislation is likely to ma...   \n",
       "4      The economic turnaround started at the end of ...   \n",
       "...                                                  ...   \n",
       "10234  Under the ruling of the Supreme Court, any lob...   \n",
       "10235  There are a larger number of shark attacks in ...   \n",
       "10236  Democrats have now become the party of the Atl...   \n",
       "10237  Says an alternative to Social Security that op...   \n",
       "10238  On lifting the U.S. Cuban embargo and allowing...   \n",
       "\n",
       "                                                  triple  \n",
       "0                                                    NaN  \n",
       "1                                                    NaN  \n",
       "2                                                    NaN  \n",
       "3                                                    NaN  \n",
       "4                                                    NaN  \n",
       "...                                                  ...  \n",
       "10234                                                NaN  \n",
       "10235                                                NaN  \n",
       "10236                                                NaN  \n",
       "10237  [['County', 'location/hud_county_place/county'...  \n",
       "10238                                                NaN  \n",
       "\n",
       "[10239 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93bae9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sparqlwrapper\n",
    "# https://rdflib.github.io/sparqlwrapper/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "415d0282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "\n",
    "def fb_to_common(freebase_id):\n",
    "    endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "    query = \\\n",
    "    '''SELECT ?sLabel WHERE { \n",
    "        ?s wdt:P646 \"''' + freebase_id + '''\".\n",
    "        SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "    }\n",
    "    LIMIT 1'''\n",
    "    res = get_results(endpoint_url, query)\n",
    "    try:\n",
    "        res = res['results']['bindings'][0]['sLabel']['value']\n",
    "        return res\n",
    "    except:\n",
    "        return \"No result\"\n",
    "\n",
    "def common_to_fb(common_name):\n",
    "    endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "    \n",
    "    if common_name.islower():\n",
    "        common_name = common_name.capitalize() + \"s\"\n",
    "\n",
    "    query = '''\n",
    "    SELECT ?fbid WHERE { \n",
    "        ?s wdt:P373 \"''' + common_name + '''\".\n",
    "    OPTIONAL {\n",
    "        ?s wdt:P646 ?fbid .\n",
    "        }\n",
    "    SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "    }\n",
    "    LIMIT 1'''\n",
    "    res = get_results(endpoint_url, query)\n",
    "    try:\n",
    "        res = res['results']['bindings'][0]['fbid']['value']\n",
    "        return res\n",
    "    except:\n",
    "        return common_name + \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7498b47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./liar_dataset_triples/train.csv\", index_col=0)\n",
    "valid = pd.read_csv(\"./liar_dataset_triples/valid.csv\", index_col=0)\n",
    "test = pd.read_csv(\"./liar_dataset_triples/test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "20708079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    df = df.dropna()\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.triple = df.triple.apply(lambda x: eval(x))\n",
    "    df = df.reset_index()\n",
    "    df = df[[\"id\", \"label\", \"triple\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "d71e296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_df(df):\n",
    "    expanded_df = pd.DataFrame(columns=[\"text_id\", \"head\", \"relation\", \"tail\", \"label\"])\n",
    "    for text_id, label, triples in df.values:\n",
    "        for h, r, t in triples:\n",
    "            expanded_df = expanded_df.append({\n",
    "                \"text_id\": text_id, \n",
    "                \"head\": h, \n",
    "                \"relation\": r, \n",
    "                \"tail\": t, \n",
    "                \"label\": label\n",
    "            }, ignore_index=True)\n",
    "    return expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "great-nurse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 830 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.2.1-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.9.3 soupsieve-2.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bed2ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# desktop user-agent\n",
    "USER_AGENT = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:65.0) Gecko/20100101 Firefox/65.0\"\n",
    "# mobile user-agent\n",
    "MOBILE_USER_AGENT = \"Mozilla/5.0 (Linux; Android 7.0; SM-G930V Build/NRD90M) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.125 Mobile Safari/537.36\"\n",
    "\n",
    "def google(query):\n",
    "    query = query.replace(' ', '+')\n",
    "    URL = f\"https://google.com/search?q={query}&hl=en\"\n",
    "    \n",
    "    headers = {\"user-agent\" : USER_AGENT}\n",
    "    resp = requests.get(URL, headers=headers)\n",
    "    \n",
    "    if resp.status_code == 200:\n",
    "        soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "        for g in soup.find_all(\"div\", {\"class\": \"g\"}):\n",
    "            titles = g.find_all(\"h3\")\n",
    "            if titles:\n",
    "                text = titles[0].text\n",
    "                if \"Wikipedia\" in text:\n",
    "                    return text[:-12]\n",
    "                if \"Ballotpedia\" in text:\n",
    "                    return text[:-14]\n",
    "    if resp.status_code == 429:\n",
    "        print(\"Blocked!\")\n",
    "        return False\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d59665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def google_triples(df):\n",
    "\n",
    "    # iterate list of list \n",
    "    for i, pair in enumerate(tqdm(df[[\"head\", \"tail\"]].values)):\n",
    "        h = google(pair[0])\n",
    "        t = google(pair[-1])\n",
    "        if not bool(h) and not bool(t):\n",
    "            return df\n",
    "        time.sleep(2.1)\n",
    "        df.at[i, 'head'] = h\n",
    "        df.at[i, 'tail'] = t\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "cf00bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"Scott Walker (Singer)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "e056d4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scott Walker'"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_par(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "d6883ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scott Walker'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'.\\(.*\\)', \"\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "f6073e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_par(t):\n",
    "    return re.sub(r'.\\(.*\\)', \"\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "18aca944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df, name):\n",
    "    df = clean_df(df)\n",
    "    df = expand_df(df)\n",
    "    df = google_triples(df)\n",
    "    df['head'] = df[\"head\"].apply(lambda x: remove_par(x))\n",
    "    df['tail'] = df[\"tail\"].apply(lambda x: remove_par(x))\n",
    "    df.to_csv(\"./liar_dataset_triples/\" + name + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "2ac889d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./liar_dataset_triples/train.csv\", index_col=0)\n",
    "valid = pd.read_csv(\"./liar_dataset_triples/valid.csv\", index_col=0)\n",
    "test = pd.read_csv(\"./liar_dataset_triples/test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "ce7867fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16723ee5d1614b6281c806be2d4131ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=453.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80cc6f3e0a1741899b6a938710c0db9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=178.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673ac0194e6a478e8743be3527f5653d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=201.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform(train, \"train_google\")\n",
    "transform(valid, \"valid_google\")\n",
    "transform(test, \"test_google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "740a6126",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_train = pd.read_csv(\"./liar_dataset_triples/train_google.csv\", index_col=0)\n",
    "google_valid = pd.read_csv(\"./liar_dataset_triples/valid_google.csv\", index_col=0)\n",
    "google_test = pd.read_csv(\"./liar_dataset_triples/test_google.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "877c92ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6873.json</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>President of the United States</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7976.json</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>President of the United States</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2354.json</td>\n",
       "      <td>Kristi Thibaut</td>\n",
       "      <td>organization/role/leaders./organization/leader...</td>\n",
       "      <td>Acorn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2354.json</td>\n",
       "      <td>Kristi Thibaut</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>State+Rep.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>980.json</td>\n",
       "      <td>Timothy Geithner</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>Secretary</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>1550.json</td>\n",
       "      <td>Perry</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>.gov</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>6032.json</td>\n",
       "      <td>Stan Wise</td>\n",
       "      <td>organization/role/leaders./organization/leader...</td>\n",
       "      <td>Georgia Public Service Commission</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>3744.json</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>President of the United States</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>4388.json</td>\n",
       "      <td>Fung</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>Mayor</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>3959.json</td>\n",
       "      <td>County</td>\n",
       "      <td>location/hud_county_place/county</td>\n",
       "      <td>Galveston, Texas</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       text_id              head  \\\n",
       "0    6873.json      Barack Obama   \n",
       "1    7976.json      Barack Obama   \n",
       "2    2354.json    Kristi Thibaut   \n",
       "3    2354.json    Kristi Thibaut   \n",
       "4     980.json  Timothy Geithner   \n",
       "..         ...               ...   \n",
       "448  1550.json             Perry   \n",
       "449  6032.json         Stan Wise   \n",
       "450  3744.json      Barack Obama   \n",
       "451  4388.json              Fung   \n",
       "452  3959.json            County   \n",
       "\n",
       "                                              relation  \\\n",
       "0    people/person/employment_history./business/emp...   \n",
       "1    people/person/employment_history./business/emp...   \n",
       "2    organization/role/leaders./organization/leader...   \n",
       "3    people/person/employment_history./business/emp...   \n",
       "4    people/person/employment_history./business/emp...   \n",
       "..                                                 ...   \n",
       "448  people/person/employment_history./business/emp...   \n",
       "449  organization/role/leaders./organization/leader...   \n",
       "450  people/person/employment_history./business/emp...   \n",
       "451  people/person/employment_history./business/emp...   \n",
       "452                   location/hud_county_place/county   \n",
       "\n",
       "                                  tail  label  \n",
       "0       President of the United States  False  \n",
       "1       President of the United States   True  \n",
       "2                                Acorn   True  \n",
       "3                           State+Rep.   True  \n",
       "4                            Secretary  False  \n",
       "..                                 ...    ...  \n",
       "448                               .gov   True  \n",
       "449  Georgia Public Service Commission   True  \n",
       "450     President of the United States   True  \n",
       "451                              Mayor  False  \n",
       "452                   Galveston, Texas   True  \n",
       "\n",
       "[453 rows x 5 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "66b6b4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "o_train = clean_df(train)\n",
    "o_train = expand_df(o_train)\n",
    "o_valid = clean_df(valid)\n",
    "o_valid = expand_df(o_valid)\n",
    "o_test = clean_df(test)\n",
    "o_test = expand_df(o_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "1e22e402",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_train[\"o_head\"] = o_train[\"head\"]\n",
    "google_train[\"o_tail\"] = o_train[\"tail\"]\n",
    "google_valid[\"o_head\"] = o_valid[\"head\"]\n",
    "google_valid[\"o_tail\"] = o_valid[\"tail\"]\n",
    "google_test[\"o_head\"] = o_test[\"head\"]\n",
    "google_test[\"o_tail\"] = o_test[\"tail\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "053c260c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "to_csv() got an unexpected keyword argument 'index_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-303-d31c07724998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgoogle_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./liar_dataset_triples/train_cleaning.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgoogle_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./liar_dataset_triples/valid_cleaning.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgoogle_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./liar_dataset_triples/test_cleaning.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: to_csv() got an unexpected keyword argument 'index_col'"
     ]
    }
   ],
   "source": [
    "google_train.to_csv(\"./liar_dataset_triples/train_cleaning.csv\")\n",
    "google_valid.to_csv(\"./liar_dataset_triples/valid_cleaning.csv\")\n",
    "google_test.to_csv(\"./liar_dataset_triples/test_cleaning.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "cc4953b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fix = pd.read_csv(\"./liar_dataset_triples/test_fix_1.csv\", sep=\";\", header=0,  error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "80fb77d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hash(df):\n",
    "    fb_hash = []\n",
    "    for h in df['head'].values:\n",
    "        fb = common_to_fb(h)\n",
    "        if not \"/m/\" in fb:\n",
    "            fb_hash.append(h)\n",
    "        else:\n",
    "            fb_hash.append(fb)\n",
    "    df[\"fb_head\"] = fb_hash\n",
    "    fb_hash = []\n",
    "    for t in df['tail'].values:\n",
    "        fb = common_to_fb(t)\n",
    "        if not \"/m/\" in fb:\n",
    "            fb_hash.append(t)\n",
    "        else:\n",
    "            fb_hash.append(fb)\n",
    "    df[\"fb_tail\"] = fb_hash\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "2bb9cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fix = add_hash(test_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "977c83e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_fix = add_hash(google_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "061ef347",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fix = add_hash(google_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "aa4cd096",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fix.to_csv(\"./liar_dataset_triples/train_processed.csv\")\n",
    "valid_fix.to_csv(\"./liar_dataset_triples/valid_processed.csv\")\n",
    "test_fix.to_csv(\"./liar_dataset_triples/test_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "fcadcd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_fix = pd.read_csv(\"./liar_dataset_triples/valid_processed.csv\", index_col=0, header=0,  error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed71e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fix = pd.read_csv(\"./liar_dataset_triples/test_hashed.csv\", sep=\";\", header=0,  error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "d0372daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_fix = valid_fix.replace(\"Gov.\", \"governor\")\n",
    "valid_fix = valid_fix.replace(\".gov\", \"governor\")\n",
    "valid_fix = valid_fix.replace(\"Governor\", \"governor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "d0a929c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(valid_fix.shape[0]-1):\n",
    "    if sum(test_fix['head'] == valid_fix.at[i, 'head']) > 0:\n",
    "        valid_fix.at[i, 'fb_head'] = test_fix[test_fix['head'] == valid_fix.at[i, 'head']]['fb_head'].values[0]\n",
    "        \n",
    "    if sum(test_fix['tail'] == valid_fix.at[i, 'tail']) > 0:\n",
    "        valid_fix.at[i, 'fb_tail'] = test_fix[test_fix['tail'] == valid_fix.at[i, 'tail']]['fb_tail'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "52330fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_fix.to_csv(\"./liar_dataset_triples/valid_hashed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "af7a47a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fix = train_fix.replace(\"Gov.\", \"governor\")\n",
    "train_fix = train_fix.replace(\".gov\", \"governor\")\n",
    "train_fix = train_fix.replace(\"Governor\", \"governor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "544973af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chris Christie'"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_to_common(\"/m/0f8t6k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "97fef091",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_fix.shape[0]-1):\n",
    "    if sum(valid_fix['head'] == train_fix.at[i, 'head']) > 0:\n",
    "        train_fix.at[i, 'fb_head'] = valid_fix[valid_fix['head'] == train_fix.at[i, 'head']]['fb_head'].values[0]\n",
    "        \n",
    "    if sum(valid_fix['tail'] == train_fix.at[i, 'tail']) > 0:\n",
    "        train_fix.at[i, 'fb_tail'] = valid_fix[valid_fix['tail'] == train_fix.at[i, 'tail']]['fb_tail'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "a56c00e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fix.to_csv(\"./liar_dataset_triples/train_hashed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "426f5ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['As Virginias governor, Allen cut spending and waste with bipartisan support.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.id == \"5401.json\"].text.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a94a9",
   "metadata": {},
   "source": [
    "# FakeNewsNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e329a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob(\"./fakenewsnet/*/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af6b2177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"text\", \"source\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c672872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(data):\n",
    "    text = data['text']\n",
    "    label = \"false\" if (path.split(\"\\\\\")[-2] == \"FakeNewsContent\") else \"true\"\n",
    "    source = path.split(\"\\\\\")[1]\n",
    "    return {\"text\":text, \"source\": source, \"label\": label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a22dcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 422/422 [00:02<00:00, 150.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "for path in tqdm(paths):\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    content = get_content(data)\n",
    "    df = df.append(content, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fc8f44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    BuzzFeed:\n",
      "    num articles: 182,\n",
      "        false: 91,\n",
      "        true: 91\n",
      "    \n",
      "    PolitiFact:\n",
      "    num articles: 240,\n",
      "        false: 120,\n",
      "        true: 120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "buzzfeed = df[df.source == \"BuzzFeed\"]\n",
    "politifact = df[df.source == \"PolitiFact\"]\n",
    "print(f\"\"\"\n",
    "    BuzzFeed:\n",
    "    num articles: {buzzfeed.shape[0]},\n",
    "        false: {sum(buzzfeed.label == \"false\")},\n",
    "        true: {sum(buzzfeed.label == \"true\")}\n",
    "    \n",
    "    PolitiFact:\n",
    "    num articles: {politifact.shape[0]},\n",
    "        false: {sum(politifact.label == \"false\")},\n",
    "        true: {sum(politifact.label == \"true\")}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "29db6aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./fakenewsnet/clean_fakenewsnet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "975da238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                \n",
       "source    PolitiFact\n",
       "label          false\n",
       "Name: 219, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[219]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22bc329",
   "metadata": {},
   "source": [
    "## Post processing\n",
    "Clean output from triple extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22cd986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(path):\n",
    "    df = pd.read_csv(paths[0])\n",
    "    return df[[\"text\", \"source\", \"label\", \"triple\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a07eaa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob(\"./fakenewsnet_triples/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7426c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(paths[0], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c709e094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "      <th>triple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>I woke up this morning to find a variation of ...</td>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>False</td>\n",
       "      <td>[['Clinton', 'organization/role/leaders./organ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Former President Bill Clinton and his Clinton ...</td>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>False</td>\n",
       "      <td>[['Bill Clinton', 'people/person/employment_hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>After collapsing just before trying to step in...</td>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Donald Trump is, well, deplorable. Hes suggest...</td>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>False</td>\n",
       "      <td>[['Obama', 'people/person/employment_history./...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Website is Down For Maintenance</td>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>419.0</td>\n",
       "      <td>As my 25th wedding anniversary approached, I t...</td>\n",
       "      <td>PolitiFact</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>420.0</td>\n",
       "      <td>Story highlights Trump was sitting in a chair ...</td>\n",
       "      <td>PolitiFact</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>421.0</td>\n",
       "      <td>Donald Trump Jr., a son of the Republican pres...</td>\n",
       "      <td>PolitiFact</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[['Trump', 'people/person/employment_history./...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[['Jason Spencer R', 'people/person/employment...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>422 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1                                               text  \\\n",
       "0             0.0  I woke up this morning to find a variation of ...   \n",
       "1             1.0  Former President Bill Clinton and his Clinton ...   \n",
       "2             2.0  After collapsing just before trying to step in...   \n",
       "3             3.0  Donald Trump is, well, deplorable. Hes suggest...   \n",
       "4             4.0                    Website is Down For Maintenance   \n",
       "..            ...                                                ...   \n",
       "419         419.0  As my 25th wedding anniversary approached, I t...   \n",
       "420         420.0  Story highlights Trump was sitting in a chair ...   \n",
       "421         421.0  Donald Trump Jr., a son of the Republican pres...   \n",
       "219           NaN                                                NaN   \n",
       "244           NaN                                                NaN   \n",
       "\n",
       "         source  label                                             triple  \n",
       "0      BuzzFeed  False  [['Clinton', 'organization/role/leaders./organ...  \n",
       "1      BuzzFeed  False  [['Bill Clinton', 'people/person/employment_hi...  \n",
       "2      BuzzFeed  False                                                NaN  \n",
       "3      BuzzFeed  False  [['Obama', 'people/person/employment_history./...  \n",
       "4      BuzzFeed  False                                                NaN  \n",
       "..          ...    ...                                                ...  \n",
       "419  PolitiFact   True                                                NaN  \n",
       "420  PolitiFact   True                                                NaN  \n",
       "421  PolitiFact   True                                                NaN  \n",
       "219         NaN    NaN  [['Trump', 'people/person/employment_history./...  \n",
       "244         NaN    NaN  [['Jason Spencer R', 'people/person/employment...  \n",
       "\n",
       "[422 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f048cedd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sen. Chuck Schumers money could give Democrats some breathing room as they slash expensive ad buys in Florida and Ohio.  Getty Schumer transfers millions to Dems in bid for Senate takeoverChuck Schumer is sitting on a mountain of cash. And now hes starting to dole it out to fellow Democrats who might make him majority leader.The New York senator is transferring 1 million to the Senate Democrats campaign arm on Tuesday. Hes also given 3.2 million to state parties over the past week, Democratic sources said.Story Continued BelowEarlier this month, Schumer shifted an additional 2 million from his campaign war chest to the Democratic Senatorial Campaign Committee. Altogether in September, Schumer has transferred 6.2 million of the 27 million he has on hand to help Democratic hopefuls.Republicans control 54 seats, but Democrats are favored to win three back, so control of the chamber is seen as a tossup. As the party begins making difficult decisions about where to spend and where to cut, a significant transfer from Schumer could go a long way.The Kochs do not have a finite amount of money, they have unlimited money. We have a finite amount of money, said Senate Minority Leader Harry Reid DNev. in an interview on Monday. Were just trying to allocate our resources so theyre meaningful to us and our candidates.Schumers money could give Democrats some breathing room as they slash expensive ad buys in Florida and Ohio and eye instead cheaper races in North Carolina and Missouri. No one has more to gain from a Democratic takeover of the Senate than Schumer, who will ascend to the leader job in 2017 as Reid retires after a 12year stint as party head.Schumers donation is both a vote of confidence in his partys candidates and a reflection of Democrats future challenges. Democrats are defending 25 seats in 2018 compared with just eight GOP seats, so if Democrats come up short in November they are unlikely to take back the majority this decade.Schumer has also raised 2 million directly for candidates committees, and a joint account that he leads has collected 800,000 combined for the DSCC and individual candidates. Hes planning a fall event in New York to benefit Senate candidates thats projected to bring in upwards of another million, according to a person close to the New York senator.Schumer has been relentless, said a DSCC official.Schumer and Reid have also appeared at numerous events for Senate Majority PAC, a super PAC backing Democratic Senate hopefuls run by former aides to Reid, including his onetime chief of staff, Susan McCue. The group, which can accept unlimited donations from donors, has spent more than 30 million this cycle. Democrats complain that Republican super PACs have far outspent them.Leader Reid and Senator Schumer are working around the clock to raise awareness about the avalanche of money Republicans are pouring into Senate races through independent expenditures. The amounts are staggering, McCue said in a statement.Schumer still will have roughly 20 million on hand after the transfer. He is up for reelection in New York, with the latest polls showing him trouncing his GOP challenger by more than 40 points. However, if past is prologue, Schumer is likely to spend some money on it despite token opposition.Schumer spent about 13 million in 2010, but that was a historically bad year for Democrats. Schumers colleagues wont rule out the possibility that hell donate more to his partys Senate takeover effort.If he thinks it will make a difference, hell do it. Hes very calculating, said a Democratic senator. Chuck will be there if you need him.Sen. Debbie Stabenow DMich., a close ally of Schumer, agreed that the presumptive Democratic leader might provide more.Hes going to watch everything closely. Its my sense hes 1,000 percent committed to taking back the Senate, Stabenow said.Theres no decision yet on where the DSCC might allocate the additional money from Schumer. It could go toward races in New Hampshire, Pennsylvania or Nevada, states that are all exceedingly close, or help compete in pricey Florida. Using the cash in redleaning states is another option.Were going to make some tough decisions, which havent been made yet, Reid said.The National Republican Senatorial Committee has been outraised by the DSCC to the tune of 36 million. Outside groups like the Senate Leadership Fund are making up the difference, but Republican officials are leaning on their rank and file to help fill the campaign coffers, with McConnell coming up with nearly 4 million in transfers thus far. Sen. John Thune RS.D. made a big splash with a 2 million transfer, but even though he has millions more on hand, Thune said hell need to hang on to the rest of his cash.I dont think I can probably keep pace with Schumer, Thune said in an interview.Republicans are now trying to wring every last bit out of their members, after Sen. Richard Shelby of Alabama spurned transferring any of his 10 million. Now the GOP hopes that NRSC Vice Chairs Dean Heller of Nevada and Tom Cotton of Arkansas may make a lastminute transfer. They have yet to give money directly to the group, GOP sources said, though they have helped raise funds directly for the NRSC. The third vice chair Joni Ernst of Iowa gave last week, an aide said Tuesday morning.Republicans, however, simply dont have their own Chuck Schumer. Instead, they are relying on a tightening presidential race, deeppocketed outside groups and candidates who are running far ahead of Trump to eke out a win.Hes a machine, Senate Majority Whip John Cornyn of Texas said of Schumer, his workout partner. But it may not make a difference, the Texan added.Authors'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[397].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a469cc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\oddgu\\programming\\text2rdf\\venv\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    if type(df.iloc[i].text) != np.float:\n",
    "        if \"National Republican Senatorial Committee\" in df.iloc[i].text:\n",
    "            print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e0de9854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\oddgu\\programming\\text2rdf\\venv\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "clean = pd.DataFrame(columns=[\"id_text\",\"text\", \"source\", \"label\", \"triple\"])\n",
    "for i in range(df.shape[0]):\n",
    "    if type(df.iloc[i].text) != np.float:\n",
    "        t = df.iloc[i].values\n",
    "        clean = clean.append({\n",
    "                \"id_text\": i,\n",
    "                \"text\": t[1],\n",
    "                \"source\": t[2],\n",
    "                \"label\": t[3],\n",
    "                \"triple\": t[4]\n",
    "            }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "83d2b9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./fakenewsnet_triples\\\\clean_fakenewsnet_triple.csv']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9a6facf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean.to_csv(\"./fakenewsnet_triples/fakenewsnet_triples_trimmed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a33f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed = pd.read_csv(\"./fakenewsnet_triples/fakenewsnet_triples_trimmed.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c718279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    df = df.dropna()\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.triple = df.triple.apply(lambda x: eval(x))\n",
    "    df = df.reset_index()\n",
    "    df = df[[\"id_text\", \"label\", \"triple\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f0c7ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_df(df):\n",
    "    expanded_df = pd.DataFrame(columns=[\"text_id\", \"head\", \"relation\", \"tail\", \"label\"])\n",
    "    for text_id, label, triples in df.values:\n",
    "        for h, r, t in triples:\n",
    "            expanded_df = expanded_df.append({\n",
    "                \"text_id\": text_id, \n",
    "                \"head\": h, \n",
    "                \"relation\": r, \n",
    "                \"tail\": t, \n",
    "                \"label\": label\n",
    "            }, ignore_index=True)\n",
    "    return expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1856e6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def remove_par(t):\n",
    "    return re.sub(r'.\\(.*\\)', \"\", t)\n",
    "\n",
    "def clean_df(df):\n",
    "    df = df.dropna()\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.triple = df.triple.apply(lambda x: eval(x))\n",
    "    df = df.reset_index()\n",
    "    df = df[[\"id_text\", \"label\", \"triple\"]]\n",
    "    return df\n",
    "\n",
    "def expand_df(df):\n",
    "    expanded_df = pd.DataFrame(columns=[\"id_text\", \"head\", \"relation\", \"tail\", \"label\"])\n",
    "    for text_id, label, triples in df.values:\n",
    "        for h, r, t in triples:\n",
    "            expanded_df = expanded_df.append({\n",
    "                \"text_id\": text_id, \n",
    "                \"head\": h, \n",
    "                \"relation\": r, \n",
    "                \"tail\": t, \n",
    "                \"label\": label\n",
    "            }, ignore_index=True)\n",
    "    return expanded_df\n",
    "\n",
    "def google_triples(df):\n",
    "\n",
    "    # iterate list of list \n",
    "    for i, pair in enumerate(tqdm(df[[\"head\", \"tail\"]].values)):\n",
    "        h = google(pair[0])\n",
    "        t = google(pair[-1])\n",
    "        if not bool(h) and not bool(t):\n",
    "            return df\n",
    "        time.sleep(2.1)\n",
    "        df.at[i, 'head'] = h\n",
    "        df.at[i, 'tail'] = t\n",
    "    return df\n",
    "\n",
    "def transform(df, name):\n",
    "    df = clean_df(df)\n",
    "    df = expand_df(df)\n",
    "    df = google_triples(df)\n",
    "    df['head'] = df[\"head\"].apply(lambda x: remove_par(x))\n",
    "    df['tail'] = df[\"tail\"].apply(lambda x: remove_par(x))\n",
    "    df.to_csv(\"./fakenewsnet_triples/\" + name + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "focal-sequence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Backstages auditions in Houston, Texas, include theater, film, television, commercials, and voiceover roles. New Houston auditions are posted to Backstage.com daily. You can further refine your search by age range, production type, gender, union status and more, and save your search to have new Dallas casting notices sent directly to your inb'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmed[trimmed.id_text == 251].text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d9a015f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oddgunnaraspaas/Personal/multiRelational-GraphStar/venv/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/oddgunnaraspaas/Personal/multiRelational-GraphStar/venv/lib/python3.7/site-packages/pandas/core/generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "100%|██████████| 1000/1000 [1:38:26<00:00,  5.91s/it]\n"
     ]
    }
   ],
   "source": [
    "transform(trimmed, \"googled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "drawn-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "googled = pd.read_csv(\"./fakenewsnet_triples/googled.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "massive-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hash(df):\n",
    "    fb_hash = []\n",
    "    for h in df['head'].values:\n",
    "        fb = common_to_fb(h)\n",
    "        if not \"/m/\" in fb:\n",
    "            fb_hash.append(h)\n",
    "        else:\n",
    "            fb_hash.append(fb)\n",
    "    df[\"fb_head\"] = fb_hash\n",
    "    fb_hash = []\n",
    "    for t in df['tail'].values:\n",
    "        fb = common_to_fb(t)\n",
    "        if not \"/m/\" in fb:\n",
    "            fb_hash.append(t)\n",
    "        else:\n",
    "            fb_hash.append(fb)\n",
    "    df[\"fb_tail\"] = fb_hash\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "functioning-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashed = add_hash(googled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "accredited-belarus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_text</th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>label</th>\n",
       "      <th>text_id</th>\n",
       "      <th>fb_head</th>\n",
       "      <th>fb_tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Bill Clinton</td>\n",
       "      <td>organization/role/leaders./organization/leader...</td>\n",
       "      <td>NPR</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/m/0157m</td>\n",
       "      <td>NPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Bill Clinton</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>President of the United States</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/m/0157m</td>\n",
       "      <td>President of the United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Marsha Blackburn</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>Rep</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/m/01fnkt</td>\n",
       "      <td>/m/07r8g3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Bate</td>\n",
       "      <td>organization/role/leaders./organization/leader...</td>\n",
       "      <td>American Enterprise Institute</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Roger Bate</td>\n",
       "      <td>/m/0p8q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>Candidate</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>Candidate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>William H. Seward</td>\n",
       "      <td>organization/role/leaders./organization/leader...</td>\n",
       "      <td>Republican Party</td>\n",
       "      <td>True</td>\n",
       "      <td>415.0</td>\n",
       "      <td>/m/0k_2z</td>\n",
       "      <td>Republican Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>John Tyler</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>President of the United States</td>\n",
       "      <td>True</td>\n",
       "      <td>415.0</td>\n",
       "      <td>/m/042dk</td>\n",
       "      <td>President of the United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>President of the United States</td>\n",
       "      <td>True</td>\n",
       "      <td>415.0</td>\n",
       "      <td>/m/0cqt90</td>\n",
       "      <td>President of the United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>President of the United States</td>\n",
       "      <td>True</td>\n",
       "      <td>415.0</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>President of the United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>King</td>\n",
       "      <td>True</td>\n",
       "      <td>416.0</td>\n",
       "      <td>/m/0cqt90</td>\n",
       "      <td>King</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_text               head  \\\n",
       "0        NaN       Bill Clinton   \n",
       "1        NaN       Bill Clinton   \n",
       "2        NaN   Marsha Blackburn   \n",
       "3        NaN         Roger Bate   \n",
       "4        NaN    Hillary Clinton   \n",
       "..       ...                ...   \n",
       "995      NaN  William H. Seward   \n",
       "996      NaN         John Tyler   \n",
       "997      NaN       Donald Trump   \n",
       "998      NaN    Hillary Clinton   \n",
       "999      NaN       Donald Trump   \n",
       "\n",
       "                                              relation  \\\n",
       "0    organization/role/leaders./organization/leader...   \n",
       "1    people/person/employment_history./business/emp...   \n",
       "2    people/person/employment_history./business/emp...   \n",
       "3    organization/role/leaders./organization/leader...   \n",
       "4    people/person/employment_history./business/emp...   \n",
       "..                                                 ...   \n",
       "995  organization/role/leaders./organization/leader...   \n",
       "996  people/person/employment_history./business/emp...   \n",
       "997  people/person/employment_history./business/emp...   \n",
       "998  people/person/employment_history./business/emp...   \n",
       "999  people/person/employment_history./business/emp...   \n",
       "\n",
       "                               tail  label  text_id          fb_head  \\\n",
       "0                               NPR  False      0.0         /m/0157m   \n",
       "1    President of the United States  False      1.0         /m/0157m   \n",
       "2                               Rep  False      1.0        /m/01fnkt   \n",
       "3     American Enterprise Institute  False      1.0       Roger Bate   \n",
       "4                         Candidate  False      1.0  Hillary Clinton   \n",
       "..                              ...    ...      ...              ...   \n",
       "995                Republican Party   True    415.0         /m/0k_2z   \n",
       "996  President of the United States   True    415.0         /m/042dk   \n",
       "997  President of the United States   True    415.0        /m/0cqt90   \n",
       "998  President of the United States   True    415.0  Hillary Clinton   \n",
       "999                            King   True    416.0        /m/0cqt90   \n",
       "\n",
       "                            fb_tail  \n",
       "0                               NPR  \n",
       "1    President of the United States  \n",
       "2                         /m/07r8g3  \n",
       "3                          /m/0p8q4  \n",
       "4                         Candidate  \n",
       "..                              ...  \n",
       "995                Republican Party  \n",
       "996  President of the United States  \n",
       "997  President of the United States  \n",
       "998  President of the United States  \n",
       "999                            King  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "variable-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fix = pd.read_csv(\"./liar_dataset_triples/test_hashed.csv\", sep=\";\", header=0,  error_bad_lines=False)\n",
    "hashed = hashed.replace(\"Gov.\", \"governor\")\n",
    "hashed = hashed.replace(\".gov\", \"governor\")\n",
    "hashed = hashed.replace(\"Governor\", \"governor\")\n",
    "for i in range(hashed.shape[0]-1):\n",
    "    if sum(test_fix['head'] == hashed.at[i, 'head']) > 0:\n",
    "        hashed.at[i, 'fb_head'] = test_fix[test_fix['head'] == hashed.at[i, 'head']]['fb_head'].values[0]\n",
    "        \n",
    "    if sum(test_fix['tail'] == hashed.at[i, 'tail']) > 0:\n",
    "        hashed.at[i, 'fb_tail'] = test_fix[test_fix['tail'] == hashed.at[i, 'tail']]['fb_tail'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "antique-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fix = pd.read_csv(\"./liar_dataset_triples/valid_hashed.csv\", sep=\";\", header=0,  error_bad_lines=False)\n",
    "\n",
    "\n",
    "for i in range(hashed.shape[0]-1):\n",
    "    if sum(test_fix['head'] == hashed.at[i, 'head']) > 0:\n",
    "        hashed.at[i, 'fb_head'] = test_fix[test_fix['head'] == hashed.at[i, 'head']]['fb_head'].values[0]\n",
    "        \n",
    "    if sum(test_fix['tail'] == hashed.at[i, 'tail']) > 0:\n",
    "        hashed.at[i, 'fb_tail'] = test_fix[test_fix['tail'] == hashed.at[i, 'tail']]['fb_tail'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "driven-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(base, target):\n",
    "    for i in range(base.shape[0]-1):\n",
    "        for x in [\"head\", \"tail\"]:\n",
    "            for y in [\"head\", \"tail\"]:\n",
    "                if sum(test_fix[x] == hashed.at[i, y]) > 0:\n",
    "                    hashed.at[i, f'fb_{y}'] = test_fix[test_fix[x] == hashed.at[i, y]]['fb_head'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "consistent-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIAR_train = pd.read_csv(\"./liar_dataset_triples/train_hashed.csv\", sep=\";\", header=0,  error_bad_lines=False)\n",
    "LIAR_valid = pd.read_csv(\"./liar_dataset_triples/valid_hashed.csv\", sep=\";\", header=0,  error_bad_lines=False)\n",
    "LIAR_test = pd.read_csv(\"./liar_dataset_triples/test_hashed.csv\", sep=\";\", header=0,  error_bad_lines=False)\n",
    "\n",
    "compare(hashed, LIAR_train)\n",
    "compare(hashed, LIAR_valid)\n",
    "compare(hashed, LIAR_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "aging-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(q):\n",
    "    return '''\n",
    "    SELECT ?fbid WHERE { \n",
    "        ?s wdt:P373 \"''' + q + '''\".\n",
    "    OPTIONAL {\n",
    "        ?s wdt:P646 ?fbid .\n",
    "        }\n",
    "    SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "    }\n",
    "    LIMIT 1'''\n",
    "\n",
    "def common_to_fb(common_name):\n",
    "    endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "    query = get_query(common_name)\n",
    "    res = get_results(endpoint_url, query)\n",
    "    try:\n",
    "        res = res['results']['bindings'][0]['fbid']['value']\n",
    "        return res\n",
    "    except:\n",
    "        return common_name\n",
    "    \n",
    "def fb_convert(common_name):\n",
    "    # base\n",
    "    res = common_to_fb(common_name)\n",
    "    if res.__contains__(\"/m/\"):\n",
    "        return res\n",
    "    res = common_to_fb(common_name.lower())\n",
    "    if res.__contains__(\"/m/\"):\n",
    "        return res\n",
    "    if common_name[-1] == \"s\":\n",
    "        end = \"\"\n",
    "    else:\n",
    "        end = \"s\"\n",
    "    res = common_to_fb(common_name.capitalize() + end)\n",
    "    if res.__contains__(\"/m/\"):\n",
    "        return res\n",
    "    return common_name\n",
    "\n",
    "def add_hash(df):\n",
    "    fb_hash = []\n",
    "    for h in df['head'].values:\n",
    "        fb = fb_convert(h)\n",
    "        if not \"/m/\" in fb:\n",
    "            fb_hash.append(h)\n",
    "        else:\n",
    "            fb_hash.append(fb)\n",
    "    df[\"fb_head\"] = fb_hash\n",
    "    fb_hash = []\n",
    "    for t in df['tail'].values:\n",
    "        fb = fb_convert(t)\n",
    "        if not \"/m/\" in fb:\n",
    "            fb_hash.append(t)\n",
    "        else:\n",
    "            fb_hash.append(fb)\n",
    "    df[\"fb_tail\"] = fb_hash\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "irish-blame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank\n"
     ]
    }
   ],
   "source": [
    "for e in bad_heads:\n",
    "    res = fb_convert(e)\n",
    "    if res.__contains__(\"/m/\"):\n",
    "        print(e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "suspected-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashed2 = add_hash(hashed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "french-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIAR_train = pd.read_csv(\"./liar_dataset_triples/train_hashed.csv\", sep=\";\", header=0,  error_bad_lines=False)\n",
    "LIAR_valid = pd.read_csv(\"./liar_dataset_triples/valid_hashed.csv\", sep=\";\", header=0,  error_bad_lines=False)\n",
    "LIAR_test = pd.read_csv(\"./liar_dataset_triples/test_hashed.csv\", sep=\";\", header=0,  error_bad_lines=False)\n",
    "\n",
    "compare(hashed2, LIAR_train)\n",
    "compare(hashed2, LIAR_valid)\n",
    "compare(hashed2, LIAR_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "naked-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_heads = np.unique([e for e in hashed2.fb_head.values if not e.startswith(\"/m/\")])\n",
    "bad_tails = np.unique([e for e in hashed2.fb_tail.values if not e.startswith(\"/m/\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "perfect-arthritis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "print(len(bad_heads))\n",
    "print(len(bad_tails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "square-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = hashed2[\"fb_head\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "separated-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = []\n",
    "for e in test:\n",
    "    if e.startswith(\"/m/\"):\n",
    "        mask.append(False)\n",
    "    else:\n",
    "        mask.append(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "dynamic-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3         Roger Bate\n",
       "9                HES\n",
       "18      Nafeez Ahmed\n",
       "31          Michelle\n",
       "32       Peter Allen\n",
       "           ...      \n",
       "986        Friedrich\n",
       "987        Friedrich\n",
       "988        Friedrich\n",
       "989    Simone Wendel\n",
       "993    James K. Polk\n",
       "Name: fb_head, Length: 291, dtype: object"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashed2[\"fb_head\"][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "nominated-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [e for e in test.values if not e.startswith(\"/m\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "immune-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [e.replace(\"+\", \" \") for e in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# desktop user-agent\n",
    "USER_AGENT = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:65.0) Gecko/20100101 Firefox/65.0\"\n",
    "# mobile user-agent\n",
    "MOBILE_USER_AGENT = \"Mozilla/5.0 (Linux; Android 7.0; SM-G930V Build/NRD90M) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.125 Mobile Safari/537.36\"\n",
    "\n",
    "def google(query):\n",
    "    query = query.replace(' ', '+')\n",
    "    URL = f\"https://google.com/search?q={query}&hl=en\"\n",
    "    \n",
    "    headers = {\"user-agent\" : USER_AGENT}\n",
    "    resp = requests.get(URL, headers=headers)\n",
    "    \n",
    "    if resp.status_code == 200:\n",
    "        soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "        for g in soup.find_all(\"div\", {\"class\": \"g\"}):\n",
    "            titles = g.find_all(\"h3\")\n",
    "            if titles:\n",
    "                text = titles[0].text\n",
    "                if \"Wikipedia\" in text:\n",
    "                    return text[:-12]\n",
    "                if \"Ballotpedia\" in text:\n",
    "                    return text[:-14]\n",
    "    if resp.status_code == 429:\n",
    "        print(\"Blocked!\")\n",
    "        return False\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "moral-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# desktop user-agent\n",
    "USER_AGENT = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:65.0) Gecko/20100101 Firefox/65.0\"\n",
    "# mobile user-agent\n",
    "MOBILE_USER_AGENT = \"Mozilla/5.0 (Linux; Android 7.0; SM-G930V Build/NRD90M) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.125 Mobile Safari/537.36\"\n",
    "\n",
    "\n",
    "def name_to_wiki(name):\n",
    "    query = name.replace(' ', '+')\n",
    "    URL = \"https://www.wikidata.org/w/index.php?search=\" + query + \"&title=Special:Search&profile=advanced&fulltext=1&ns0=1&ns120=1\"\n",
    "    headers = {\"user-agent\" : USER_AGENT}\n",
    "    resp = requests.get(URL, headers=headers)\n",
    "\n",
    "    soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "    if soup.find(\"p\", {\"class\": \"mw-search-nonefound\"}) == None:\n",
    "        identifier = soup.find_all(\"span\", {\"class\": \"wb-itemlink-id\"})[0].text.strip(\"()\")\n",
    "        URL2 = \"https://www.wikidata.org/wiki/\" + identifier\n",
    "        resp = requests.get(URL2, headers=headers)\n",
    "        soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "        has_fb = soup.find(\"div\", {\"id\": \"P646\"})\n",
    "        if has_fb != None:\n",
    "            fb_id = has_fb.find(\"a\", {\"class\": \"wb-external-id external\"}).text\n",
    "            return fb_id\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "finished-daisy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x7fec02345598>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/oddgunnaraspaas/Personal/multiRelational-GraphStar/venv/lib/python3.7/site-packages/tqdm/std.py\", line 1145, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/oddgunnaraspaas/Personal/multiRelational-GraphStar/venv/lib/python3.7/site-packages/tqdm/notebook.py\", line 275, in close\n",
      "    self.disp(bar_style='danger')\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def add_hash_wiki(df):\n",
    "    fb_hash = []\n",
    "    for h in tqdm(df['fb_head'].values):\n",
    "        if not \"/m/\" in h:\n",
    "            fb = name_to_wiki(h)\n",
    "            if \"/m/\" in fb:\n",
    "                fb_hash.append(fb)\n",
    "            else:\n",
    "                fb_hash.append(h)\n",
    "        else:\n",
    "            fb_hash.append(h)\n",
    "\n",
    "    df[\"fb_head\"] = fb_hash\n",
    "    fb_hash = []\n",
    "    for t in tqdm(df['fb_tail'].values):\n",
    "        if not \"/m/\" in t:\n",
    "            fb = name_to_wiki(t)\n",
    "            if \"/m/\" in fb:\n",
    "                fb_hash.append(fb)\n",
    "            else:\n",
    "                fb_hash.append(t)\n",
    "        else:\n",
    "            fb_hash.append(t)\n",
    "    df[\"fb_tail\"] = fb_hash\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "featured-torture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 32/1000 [00:05<02:18,  6.97it/s]Exception ignored in: <function tqdm.__del__ at 0x7fec02345598>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/oddgunnaraspaas/Personal/multiRelational-GraphStar/venv/lib/python3.7/site-packages/tqdm/std.py\", line 1145, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/oddgunnaraspaas/Personal/multiRelational-GraphStar/venv/lib/python3.7/site-packages/tqdm/notebook.py\", line 275, in close\n",
      "    self.disp(bar_style='danger')\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n",
      "100%|██████████| 1000/1000 [06:45<00:00,  2.47it/s]\n",
      "/Users/oddgunnaraspaas/Personal/multiRelational-GraphStar/venv/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "100%|██████████| 1000/1000 [06:40<00:00,  2.49it/s]\n",
      "/Users/oddgunnaraspaas/Personal/multiRelational-GraphStar/venv/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "wiki_hash = add_hash_wiki(hashed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "played-looking",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wiki_hash' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-acd810d5fbf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwiki_hash\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./fakenewsnet_triples/wiki_hashed.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'wiki_hash' is not defined"
     ]
    }
   ],
   "source": [
    "wiki_hash.to_csv(\"./fakenewsnet_triples/wiki_hashed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "worth-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_hash = pd.read_csv(\"./fakenewsnet_triples/wiki_hashed.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60abb470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.0.7-py2.py3-none-any.whl (243 kB)\n",
      "Collecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.0.1.tar.gz (8.4 kB)\n",
      "Building wheels for collected packages: et-xmlfile\n",
      "  Building wheel for et-xmlfile (setup.py): started\n",
      "  Building wheel for et-xmlfile (setup.py): finished with status 'done'\n",
      "  Created wheel for et-xmlfile: filename=et_xmlfile-1.0.1-py3-none-any.whl size=8913 sha256=3f3ea18f54ed058d8917a0b4c6d9d46cda7c1b1d67d09ef92f6404f644703087\n",
      "  Stored in directory: c:\\users\\oddgu\\appdata\\local\\pip\\cache\\wheels\\e2\\bd\\55\\048b4fd505716c4c298f42ee02dffd9496bb6d212b266c7f31\n",
      "Successfully built et-xmlfile\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.0.1 openpyxl-3.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe877eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_hash.to_excel(\"./fakenewsnet_triples/wiki_hashed.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "091e06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = pd.read_excel(\"./fakenewsnet_triples/wiki_hashed.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7e339a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual.to_csv(\"./fakenewsnet_triples/manual_fix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a97e694c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>fb_head</th>\n",
       "      <th>fb_tail</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bill Clinton</td>\n",
       "      <td>organization/role/leaders./organization/leader...</td>\n",
       "      <td>NPR</td>\n",
       "      <td>/m/0157m</td>\n",
       "      <td>/m/0c0sl</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bill Clinton</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>President of the United States</td>\n",
       "      <td>/m/0157m</td>\n",
       "      <td>/m/02mjmr</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Marsha Blackburn</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>Rep</td>\n",
       "      <td>/m/01fnkt</td>\n",
       "      <td>/m/02qkv0r</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Roger Bate</td>\n",
       "      <td>organization/role/leaders./organization/leader...</td>\n",
       "      <td>American Enterprise Institute</td>\n",
       "      <td>/m/0b23zg</td>\n",
       "      <td>/m/0p8q4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>Candidate</td>\n",
       "      <td>/m/0d06m5</td>\n",
       "      <td>/m/07r9r0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>415</td>\n",
       "      <td>William H. Seward</td>\n",
       "      <td>organization/role/leaders./organization/leader...</td>\n",
       "      <td>Republican Party</td>\n",
       "      <td>/m/0k_2z</td>\n",
       "      <td>/m/085srz</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>415</td>\n",
       "      <td>John Tyler</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>President of the United States</td>\n",
       "      <td>/m/042dk</td>\n",
       "      <td>/m/02mjmr</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>415</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>President of the United States</td>\n",
       "      <td>/m/0cqt90</td>\n",
       "      <td>/m/02mjmr</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>415</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>President of the United States</td>\n",
       "      <td>/m/0d06m5</td>\n",
       "      <td>/m/02mjmr</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>416</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>people/person/employment_history./business/emp...</td>\n",
       "      <td>King</td>\n",
       "      <td>/m/0cqt90</td>\n",
       "      <td>/m/03w9bnr</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     text_id               head  \\\n",
       "0          0       Bill Clinton   \n",
       "1          1       Bill Clinton   \n",
       "2          1   Marsha Blackburn   \n",
       "3          1         Roger Bate   \n",
       "4          1    Hillary Clinton   \n",
       "..       ...                ...   \n",
       "995      415  William H. Seward   \n",
       "996      415         John Tyler   \n",
       "997      415       Donald Trump   \n",
       "998      415    Hillary Clinton   \n",
       "999      416       Donald Trump   \n",
       "\n",
       "                                              relation  \\\n",
       "0    organization/role/leaders./organization/leader...   \n",
       "1    people/person/employment_history./business/emp...   \n",
       "2    people/person/employment_history./business/emp...   \n",
       "3    organization/role/leaders./organization/leader...   \n",
       "4    people/person/employment_history./business/emp...   \n",
       "..                                                 ...   \n",
       "995  organization/role/leaders./organization/leader...   \n",
       "996  people/person/employment_history./business/emp...   \n",
       "997  people/person/employment_history./business/emp...   \n",
       "998  people/person/employment_history./business/emp...   \n",
       "999  people/person/employment_history./business/emp...   \n",
       "\n",
       "                               tail    fb_head     fb_tail  label  \n",
       "0                               NPR   /m/0157m    /m/0c0sl  False  \n",
       "1    President of the United States   /m/0157m   /m/02mjmr  False  \n",
       "2                               Rep  /m/01fnkt  /m/02qkv0r  False  \n",
       "3     American Enterprise Institute  /m/0b23zg    /m/0p8q4  False  \n",
       "4                         Candidate  /m/0d06m5   /m/07r9r0  False  \n",
       "..                              ...        ...         ...    ...  \n",
       "995                Republican Party   /m/0k_2z   /m/085srz   True  \n",
       "996  President of the United States   /m/042dk   /m/02mjmr   True  \n",
       "997  President of the United States  /m/0cqt90   /m/02mjmr   True  \n",
       "998  President of the United States  /m/0d06m5   /m/02mjmr   True  \n",
       "999                            King  /m/0cqt90  /m/03w9bnr   True  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual[manual.text_id.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb0ad2",
   "metadata": {},
   "source": [
    "# Fake or Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d254d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob(\"./fake-or-real/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "47944233",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144fc2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
